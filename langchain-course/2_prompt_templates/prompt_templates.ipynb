{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import searchapi, google_search\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash')\n",
    "llm.invoke(\"Hi\").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['company', 'postion', 'skill', 'tone'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['company', 'postion', 'skill', 'tone'], input_types={}, partial_variables={}, template='Write a {tone} email to {company} expressing interest in the {postion} postion, mentioning {skill} as a key strength. Keep it to 4 lines max'), additional_kwargs={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\".join([\n",
    "    \"Write a {tone} email to {company} expressing interest in the {postion} postion, \",\n",
    "    \"mentioning {skill} as a key strength. Keep it to 4 lines max\"\n",
    "])\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"Write a energetic email to Bakr agency expressing interest in the ML engineer postion, mentioning ['ml', 'nlp', 'python'] as a key strength. Keep it to 4 lines max\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\n",
    "    \"tone\": \"energetic\",\n",
    "    \"company\": \"Bakr agency\",\n",
    "    \"postion\": \"ML engineer\",\n",
    "    \"skill\": [\"ml\", \"nlp\", \"python\"],\n",
    "})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Subject: ML Engineer Application - [Your Name]\n",
      "\n",
      "Thrilled to apply for the ML Engineer role! My expertise in ML, NLP, and Python aligns perfectly with your requirements. Ready to contribute impactful solutions!\n"
     ]
    }
   ],
   "source": [
    "llm.invoke(prompt).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Alright, alright, settle down folks! You came here for laughs, and I'm just the guy to disappoint you... I mean, deliver! Here are three jokes about this crazy little thing we call life:\n",
      "\n",
      "1.  Why did the existentialist cross the road? ...To get to the other side, but what does it *mean* to get to the other side? Is there an \"other side\" at all, or are we just trapped in a meaningless cycle of road-crossing? *[Stares intensely into the audience]* ...Also, he had a coupon for a free donut over there. Priorities, people!\n",
      "\n",
      "2.  They say money can't buy happiness. Well, I tried to pay my bills with a smile once. Didn't work. Turns out, you need money to buy happiness... or at least to avoid abject misery. So, basically, money *can* buy happiness... just in a roundabout, soul-crushing, capitalist kind of way.\n",
      "\n",
      "3.  I'm trying to live in the moment, but the moment keeps saying, \"Later, I've got stuff to do.\" It's like, even the present doesn't want to hang out with me! What am I, chopped liver? Maybe I should try living in the past... at least I know what to expect there. Mostly disappointment and regret. But still! Consistency!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ('system', \"you are a comedian who tells jokes about {topic}\"),\n",
    "    ('human', \"Tell me {joke_count} jokes\"),\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({\n",
    "    \"topic\": \"life\",\n",
    "    \"joke_count\": 3\n",
    "})\n",
    "\n",
    "llm.invoke(prompt).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
